{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b90848f",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    "We will be using NLTK library to illustrate basic text processing functionalities: tokenization, lemmization, stop words, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3a89c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbbe243",
   "metadata": {},
   "source": [
    "## Text Corpora\n",
    "\n",
    "A text corpus is a large body of text. Many corpora are designed to contain a careful balance of material in one or more genres.  \n",
    "\n",
    "Let's start by loading the Gutenberg corpora.  The Project Gutenberg corpora is electronic text archive, which contains some 25,000 free electronic books, hosted at http://www.gutenberg.org/. We begin by querying to see nltk.corpus.gutenberg.fileids(), the file identifiers in this corpus:\n",
    "\n",
    "[Reference](https://www.sketchengine.eu/gutenberg-corpora-2020/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab1f2fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /Users/pmui/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/pmui/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c54e3c",
   "metadata": {},
   "source": [
    "The first text is Emma by Jane Austen.  How many words does it contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2cafd92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = gutenberg.words('austen-emma.txt')\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56d48e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd5a94",
   "metadata": {},
   "source": [
    "Let's print out all info about the gutenberg corpora by looping over all the values of fileid corresponding to the gutenberg file identifiers listed earlier and then computing statistics for each text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b942878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars/word, words/sent, words/vocab\n",
      "5 25 26 austen-emma.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 26 17 austen-persuasion.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 28 22 austen-sense.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "4 34 79 bible-kjv.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 19 5 blake-poems.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "4 19 14 bryant-stories.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "4 18 12 burgess-busterbrown.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "4 20 13 carroll-alice.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 20 12 chesterton-ball.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 23 11 chesterton-brown.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 19 11 chesterton-thursday.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "4 21 25 edgeworth-parents.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 26 15 melville-moby_dick.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 52 11 milton-paradise.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "4 12 9 shakespeare-caesar.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "4 12 8 shakespeare-hamlet.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "4 12 7 shakespeare-macbeth.txt\n",
      "chars/word, words/sent, words/vocab\n",
      "5 36 12 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(\"chars/word, words/sent, words/vocab\")\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b39c9",
   "metadata": {},
   "source": [
    "The raw() function gives us the contents of the file without any linguistic processing. So, for example, len(gutenberg.raw('blake-poems.txt')) tells us how many letters occur in the text, including the spaces between words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63b83db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38153"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gutenberg.raw('blake-poems.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba8095",
   "metadata": {},
   "source": [
    "The sents() function divides the text up into its sentences, where each sentence is a list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "709894f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "macbeth_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bdc52e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Double',\n",
       " ',',\n",
       " 'double',\n",
       " ',',\n",
       " 'toile',\n",
       " 'and',\n",
       " 'trouble',\n",
       " ';',\n",
       " 'Fire',\n",
       " 'burne',\n",
       " ',',\n",
       " 'and',\n",
       " 'Cauldron',\n",
       " 'bubble']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sentences[1116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4430696f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_len = max(len(s) for s in macbeth_sentences)\n",
    "longest_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58f9e233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Doubtfull',\n",
       "  'it',\n",
       "  'stood',\n",
       "  ',',\n",
       "  'As',\n",
       "  'two',\n",
       "  'spent',\n",
       "  'Swimmers',\n",
       "  ',',\n",
       "  'that',\n",
       "  'doe',\n",
       "  'cling',\n",
       "  'together',\n",
       "  ',',\n",
       "  'And',\n",
       "  'choake',\n",
       "  'their',\n",
       "  'Art',\n",
       "  ':',\n",
       "  'The',\n",
       "  'mercilesse',\n",
       "  'Macdonwald',\n",
       "  '(',\n",
       "  'Worthie',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'Rebell',\n",
       "  ',',\n",
       "  'for',\n",
       "  'to',\n",
       "  'that',\n",
       "  'The',\n",
       "  'multiplying',\n",
       "  'Villanies',\n",
       "  'of',\n",
       "  'Nature',\n",
       "  'Doe',\n",
       "  'swarme',\n",
       "  'vpon',\n",
       "  'him',\n",
       "  ')',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Westerne',\n",
       "  'Isles',\n",
       "  'Of',\n",
       "  'Kernes',\n",
       "  'and',\n",
       "  'Gallowgrosses',\n",
       "  'is',\n",
       "  'supply',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  ',',\n",
       "  'And',\n",
       "  'Fortune',\n",
       "  'on',\n",
       "  'his',\n",
       "  'damned',\n",
       "  'Quarry',\n",
       "  'smiling',\n",
       "  ',',\n",
       "  'Shew',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'like',\n",
       "  'a',\n",
       "  'Rebells',\n",
       "  'Whore',\n",
       "  ':',\n",
       "  'but',\n",
       "  'all',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'too',\n",
       "  'weake',\n",
       "  ':',\n",
       "  'For',\n",
       "  'braue',\n",
       "  'Macbeth',\n",
       "  '(',\n",
       "  'well',\n",
       "  'hee',\n",
       "  'deserues',\n",
       "  'that',\n",
       "  'Name',\n",
       "  ')',\n",
       "  'Disdayning',\n",
       "  'Fortune',\n",
       "  ',',\n",
       "  'with',\n",
       "  'his',\n",
       "  'brandisht',\n",
       "  'Steele',\n",
       "  ',',\n",
       "  'Which',\n",
       "  'smoak',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'with',\n",
       "  'bloody',\n",
       "  'execution',\n",
       "  '(',\n",
       "  'Like',\n",
       "  'Valours',\n",
       "  'Minion',\n",
       "  ')',\n",
       "  'caru',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'out',\n",
       "  'his',\n",
       "  'passage',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'hee',\n",
       "  'fac',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'the',\n",
       "  'Slaue',\n",
       "  ':',\n",
       "  'Which',\n",
       "  'neu',\n",
       "  \"'\",\n",
       "  'r',\n",
       "  'shooke',\n",
       "  'hands',\n",
       "  ',',\n",
       "  'nor',\n",
       "  'bad',\n",
       "  'farwell',\n",
       "  'to',\n",
       "  'him',\n",
       "  ',',\n",
       "  'Till',\n",
       "  'he',\n",
       "  'vnseam',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'him',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Naue',\n",
       "  'toth',\n",
       "  \"'\",\n",
       "  'Chops',\n",
       "  ',',\n",
       "  'And',\n",
       "  'fix',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'his',\n",
       "  'Head',\n",
       "  'vpon',\n",
       "  'our',\n",
       "  'Battlements']]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in macbeth_sentences if len(s) == longest_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697108ce",
   "metadata": {},
   "source": [
    "## Brown Corpus\n",
    "\n",
    "The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University. This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, etc.  A complete list of genres for the Brown Corpus can be found at: http://icame.uib.no/brown/bcm-los.html.\n",
    "\n",
    "We can access the corpus as a list of words, or a list of sentences (where each sentence is itself just a list of words). We can optionally specify particular categories or files to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e994a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dbc1e8",
   "metadata": {},
   "source": [
    "The Brown Corpus is a convenient resource for studying systematic differences between genres, a kind of linguistic inquiry known as stylistics. Let's compare genres in their usage of modal verbs. The first step is to produce the counts for a particular genre. Remember to import nltk before doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6bb6360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can: 94 could: 87 may: 93 might: 38 must: 53 will: 389 "
     ]
    }
   ],
   "source": [
    "news_text = brown.words(categories='news')\n",
    "\n",
    "# let's find the frequency of words within a text\n",
    "news_dist = nltk.FreqDist(w.lower() for w in news_text)\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "for m in modals:\n",
    "    print(m + ':', news_dist[m], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "106cc6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what: 95 when: 169 where: 59 who: 268 why: 14 "
     ]
    }
   ],
   "source": [
    "five_w = ['what', 'when', 'where', 'who', 'why']\n",
    "for f in five_w:\n",
    "    print(f + ':', news_dist[f], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be12fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can: 39 could: 168 may: 10 might: 44 must: 55 will: 56 "
     ]
    }
   ],
   "source": [
    "fiction_text = brown.words(categories='fiction')\n",
    "fiction_dist = nltk.FreqDist(w.lower() for w in fiction_text)\n",
    "for m in modals:\n",
    "    print(m + ':', fiction_dist[m], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1ebb38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what: 186 when: 192 where: 89 who: 112 why: 42 "
     ]
    }
   ],
   "source": [
    "for f in five_w:\n",
    "    print(f + ':', fiction_dist[f], end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d3315",
   "metadata": {},
   "source": [
    "We would like to obtain counts for each genre of interest. We'll use NLTK's support for conditional frequency distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fbc7370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist((genre, word)\n",
    "                                for genre in brown.categories()\n",
    "                                for word in brown.words(categories=genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5adf9a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n",
      "          humor    16    30     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c52a47fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 what  when where   who   why \n",
      "           news    76   128    58   268     9 \n",
      "       religion    64    53    20   100    14 \n",
      "        hobbies    78   119    72   103    10 \n",
      "science_fiction    27    21    10    13     4 \n",
      "        romance   121   126    54    89    34 \n",
      "          humor    36    52    15    48     9 \n"
     ]
    }
   ],
   "source": [
    "cfd.tabulate(conditions=genres, samples=five_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b2aa7d",
   "metadata": {},
   "source": [
    "## WordNet\n",
    "\n",
    "WordNet is a semantically-oriented dictionary of English, similar to a traditional thesaurus but with a richer structure. NLTK includes the English WordNet, with 155,287 words and 117,659 synonym sets. We'll begin by looking at synonyms and how they are accessed in WordNet.\n",
    "\n",
    "### Senses and Synonyms\n",
    "\n",
    "Let's consider the words: \"car\", \"motorcar\", and \"automobile\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8be9b435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e813d54",
   "metadata": {},
   "source": [
    "Thus, motorcar has just one possible meaning and it is identified as car.n.01, the first noun sense of car. The entity car.n.01 is called a synset, or \"synonym set\", a collection of synonymous words (or \"lemmas\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "65cbe797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5f34e",
   "metadata": {},
   "source": [
    "Each word of a synset can have several meanings, e.g., car can also signify a train carriage, a gondola, or an elevator car. However, we are only interested in the single meaning that is common to all words of the above synset. Synsets also come with a prose definition and some example sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5fba7c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dce47141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he needs a car to get to work']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f8c2a",
   "metadata": {},
   "source": [
    "Although definitions help humans to understand the intended meaning of a synset, the words of the synset are often more useful for our programs. To eliminate ambiguity, we will identify these words as car.n.01.automobile, car.n.01.motorcar, and so on. This pairing of a synset with a word is called a lemma. \n",
    "\n",
    "### Lemma\n",
    "\n",
    "So a lemma again is: __pairing of a word with a syncset__.\n",
    "\n",
    "Let's see what we can do with a word's lemmas:\n",
    "- get all the lemmas for a given synset\n",
    "- look up a particular lemma\n",
    "- get the synset corresponding to a lemma\n",
    "- get the \"name\" of a lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9d4064d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('car.n.01.car'),\n",
       " Lemma('car.n.01.auto'),\n",
       " Lemma('car.n.01.automobile'),\n",
       " Lemma('car.n.01.machine'),\n",
       " Lemma('car.n.01.motorcar')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "44019411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('car.n.01.automobile')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "101db667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('car.n.01')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "378a153d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile').name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fe05c",
   "metadata": {},
   "source": [
    "Unlike the word motorcar, which is unambiguous and has one synset, the word car is ambiguous, having five synsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bce92956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68ec861e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('car')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78667792",
   "metadata": {},
   "source": [
    "For convenience, we can access all the lemmas involving the word car as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "12733d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('car.n.01.car'),\n",
       " Lemma('car.n.02.car'),\n",
       " Lemma('car.n.03.car'),\n",
       " Lemma('car.n.04.car'),\n",
       " Lemma('cable_car.n.01.car')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmas('car')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552c020",
   "metadata": {},
   "source": [
    "### WordNet Hierarchy\n",
    "\n",
    "WordNet synsets correspond to abstract concepts, and they don't always have corresponding words in English. These concepts are linked together in a hierarchy. Some concepts are very general, such as Entity, State, Event — these are called unique beginners or root synsets. Others, such as gas guzzler and hatchback, are much more specific. A small portion of a concept hierarchy is illustrated here: nodes correspond to synsets; edges indicate the hypernym/hyponym relation, i.e. the relation between superordinate and subordinate concepts.\n",
    "\n",
    "<img src=\"./images/wordnet-hierarchy.png\" width=500px>\n",
    "\n",
    "WordNet makes it easy to navigate between concepts. For example, given a concept like motorcar, we can look at the concepts that are more specific; the (immediate) hyponyms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "52354b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "motorcar = wn.synset('car.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68871e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ambulance.n.01'),\n",
       " Synset('beach_wagon.n.01'),\n",
       " Synset('bus.n.04'),\n",
       " Synset('cab.n.03'),\n",
       " Synset('compact.n.03'),\n",
       " Synset('convertible.n.01'),\n",
       " Synset('coupe.n.01'),\n",
       " Synset('cruiser.n.01'),\n",
       " Synset('electric.n.01'),\n",
       " Synset('gas_guzzler.n.01'),\n",
       " Synset('hardtop.n.01'),\n",
       " Synset('hatchback.n.01'),\n",
       " Synset('horseless_carriage.n.01'),\n",
       " Synset('hot_rod.n.01'),\n",
       " Synset('jeep.n.01'),\n",
       " Synset('limousine.n.01'),\n",
       " Synset('loaner.n.02'),\n",
       " Synset('minicar.n.01'),\n",
       " Synset('minivan.n.01'),\n",
       " Synset('model_t.n.01'),\n",
       " Synset('pace_car.n.01'),\n",
       " Synset('racer.n.02'),\n",
       " Synset('roadster.n.01'),\n",
       " Synset('sedan.n.01'),\n",
       " Synset('sport_utility.n.01'),\n",
       " Synset('sports_car.n.01'),\n",
       " Synset('stanley_steamer.n.01'),\n",
       " Synset('stock_car.n.01'),\n",
       " Synset('subcompact.n.01'),\n",
       " Synset('touring_car.n.01'),\n",
       " Synset('used-car.n.01')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_of_motorcar = motorcar.hyponyms()\n",
    "types_of_motorcar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ee007",
   "metadata": {},
   "source": [
    "We can also navigate up the hierarchy by visiting hypernyms. Some words have multiple paths, because they can be classified in more than one way. There are two paths between car.n.01 and entity.n.01 because wheeled_vehicle.n.01 can be classified as both a vehicle and a container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f8e23476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motor_vehicle.n.01')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ede14e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = motorcar.hypernym_paths()\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1bee85c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'container.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fb134450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'conveyance.n.03',\n",
       " 'vehicle.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48145274",
   "metadata": {},
   "source": [
    "We can get the most general hypernyms (or root hypernyms) of a synset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ccb4621b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.root_hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa90cfc",
   "metadata": {},
   "source": [
    "### More Lexical Relations\n",
    "\n",
    "Hypernyms and hyponyms are called lexical relations because they relate one synset to another. These two relations navigate up and down the \"is-a\" hierarchy. Another important way to navigate the WordNet network is from items to their components (__meronyms__) or to the things they are contained in (__holonyms__). For example, the parts of a tree are its trunk, crown, and so on; the part_meronyms(). The substance a tree is made of includes heartwood and sapwood; the substance_meronyms(). A collection of trees forms a forest; the member_holonyms():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('tree.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141660ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('tree.n.01').substance_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d277ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('tree.n.01').member_holonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfdc58",
   "metadata": {},
   "source": [
    "To see just how intricate things can get, consider the word mint, which has several closely-related senses. We can see that mint.n.04 is part of mint.n.02 and the substance from which mint.n.05 is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in wn.synsets('mint', wn.NOUN):\n",
    "     print(synset.name() + ':', synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b3ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('mint.n.04').part_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('mint.n.04').substance_holonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf978fc",
   "metadata": {},
   "source": [
    "There are also relationships between verbs. For example, the act of walking involves the act of stepping, so walking entails stepping. Some verbs have multiple entailments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57054d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('walk.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('eat.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('tease.v.03').entailments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa0d00",
   "metadata": {},
   "source": [
    "Some lexical relationships hold between lemmas, e.g., antonymy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('supply.n.02.supply').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('rush.v.01.rush').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('horizontal.a.01.horizontal').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56908530",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.lemma('staccato.r.01.staccato').antonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a53be",
   "metadata": {},
   "source": [
    "Additional methods for syncset can be viewed using dir():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(wn.synset('harmony.n.02'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476bed65",
   "metadata": {},
   "source": [
    "### Semantic Similarity\n",
    "\n",
    "We have seen that synsets are linked by a complex network of lexical relations. Given a particular synset, we can traverse the WordNet network to find synsets with related meanings. Knowing which words are semantically related is useful for indexing a collection of texts, so that a search for a general term like vehicle will match documents containing specific terms like limousine.\n",
    "\n",
    "Recall that each synset has one or more hypernym paths that link it to a root hypernym such as entity.n.01. Two synsets linked to the same root may have several hypernyms in common (cf 5.1). If two synsets share a very specific hypernym — one that is low down in the hypernym hierarchy — they must be closely related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "right = wn.synset('right_whale.n.01')\n",
    "orca = wn.synset('orca.n.01')\n",
    "minke = wn.synset('minke_whale.n.01')\n",
    "tortoise = wn.synset('tortoise.n.01')\n",
    "novel = wn.synset('novel.n.01')\n",
    "right.lowest_common_hypernyms(minke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "right.lowest_common_hypernyms(orca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb57d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "right.lowest_common_hypernyms(tortoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "right.lowest_common_hypernyms(novel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b74f5",
   "metadata": {},
   "source": [
    "Of course we know that whale is very specific (and baleen whale even more so), while vertebrate is more general and entity is completely general. We can quantify this concept of generality by looking up the depth of each synset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694aa888",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('baleen_whale.n.01').min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e48b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('whale.n.02').min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b964709",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('vertebrate.n.01').min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc83813",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('entity.n.01').min_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b965df8",
   "metadata": {},
   "source": [
    "Similarity measures have been defined over the collection of WordNet synsets which incorporate the above insight. For example, path_similarity assigns a score in the range 0–1 based on the shortest path that connects the concepts in the hypernym hierarchy (-1 is returned in those cases where a path cannot be found). Comparing a synset with itself will return 1. Consider the following similarity scores, relating right whale to minke whale, orca, tortoise, and novel. Although the numbers won't mean much, they decrease as we move away from the semantic space of sea creatures to inanimate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "right.path_similarity(minke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe560fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "right.path_similarity(orca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f25eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "right.path_similarity(tortoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "right.path_similarity(novel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
