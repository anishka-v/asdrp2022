{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c84cff",
   "metadata": {},
   "source": [
    "# Topic Modeling with SVD\n",
    "\n",
    "\n",
    "## What is \"topic modeling\"?\n",
    "\n",
    "Suppose you're given a large text corpus containing several documents. You'd like to know the key topics that reside in the given collection of documents without reading through each document.\n",
    "\n",
    "Topic Modeling helps you distill the information in the large text corpus into a certain number of topics. Topics are groups of words that are similar in context and are indicative of the information in the collection of documents.\n",
    "\n",
    "The general structure of the Document-Term Matrix (DTM) for a text corpus containing M documents, and N terms in all is shown below:\n",
    "\n",
    "<img src=\"./images/doc-term-matrix.png\" width=\"250px\"/>\n",
    "\n",
    "Let's parse the matrix representation:\n",
    "\n",
    "- D1, D2, ..., DM are the M documents.\n",
    "- T1, T2, ..., TN are the N terms\n",
    "\n",
    "To populate the Document-Term Matrix, let’s use the widely-used metric—the TF-IDF Score.\n",
    "\n",
    "## Term-Frequency Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "[TFIDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. tf–idf is one of the most popular term-weighting schemes today. A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries use tf–idf.\n",
    "\n",
    "- **Term Frequency**: If we rank text based on TF, we would be using the weight of a term that occurs in a document and is simply proportional to the term frequency.\n",
    "\n",
    "- **Inverse document frequency**: The specificity of a term can be quantified as an inverse function of the number of documents in which it occurs. \n",
    "\n",
    "The weighting of a term in a document based on TF-IDF can be expressed as:\n",
    "\n",
    "$$ w_{ij} = TF_{ij} log(\\frac{M}{df_j}) $$\n",
    "\n",
    "where, \n",
    "\n",
    "- $TF_{ij}$ is the number of times the term  $T_j$ occurs in the document $D_i$.\n",
    "- $df_j$ is the number of documents containing the term $T_j$\n",
    "\n",
    "Intuition: \n",
    "- A term that occurs frequently in a particular document, and rarely across the entire corpus has a higher IDF score.\n",
    "- Common words such as \"the\" or \"of\" which happens in every document will have high $df_j$ and a low overall TF-IDF $w_{ij}$ score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf4e0d",
   "metadata": {},
   "source": [
    "## Topic Modeling with SVD\n",
    "\n",
    "Singular Value Decomposition (SVD) on the the Document-Term Matrix D (of dimension MxN) gives the following three matrices:\n",
    "\n",
    "$D = U . S. V^T$\n",
    "\n",
    "Recall these 3 matrices $U$, $S$, and $V$:\n",
    "\n",
    "- $U$ has dimensions $MxM$, $S$ is a diagonal matrix with dimensions $M×N$, and $V$ has dimensions $NxN$.  \n",
    "  -- For a DTM, $U$ is also called the **document similarity matrix**. The i,j-th entry of the document similarity matrix signifies how similar document i is to document j.\n",
    "  -- The right singular vector matrix $V$, which is also called the **term topic matrix**. The topics in the text reside along the rows of this matrix. \n",
    "\n",
    "- $U$ and $V$ are orthogonal matrices. That is, $U^⊤U=I$ and $V^⊤V=I$. This also implies that all columns of $U$ and $V$ have magnitude 1 and are mutually orthogonal.\n",
    "\n",
    "- $S$ is a diagonal matrix. That is, all elements in $S$ are 0 unless they lie on the diagonal. In addition, the diagonal elements in $S$ are arranged from biggest to smallest.  The matrix of singular values $S$ which signify the relative importance of topics -- per their corresponding singular values.\n",
    "\n",
    "One may think of SVD as a black box that operates on your Document-Term Matrix (DTM) and yields 3 matrices, U, S, and V. And **the topics reside along the rows of the matrix V_T**. This is illustrated in the figure below:\n",
    "\n",
    "<img src=\"images/svd-topic-modeling.png\" width=\"500px\"/>\n",
    "\n",
    "### What is Truncated SVD or k-SVD?\n",
    "\n",
    "Suppose you have a text corpus of 150 documents. Would you prefer skimming through 150 different topics that describe the corpus, or would you be happy reading through 10 topics that can convey the content of the corpus?\n",
    "\n",
    "Well, it's often helpful to fix a small number of topics that best convey the content of the text. And this is what motivates k-SVD.\n",
    "\n",
    "As matrix multiplication requires a lot of computation, it's preferred to choose the k largest singular values, and the topics corresponding to them. The working of k-SVD is illustrated below.\n",
    "\n",
    "<img src=\"images/svd-ktopic-modeling.png\" width=\"700px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648eaab9",
   "metadata": {},
   "source": [
    "## Text Corpus SVD\n",
    "\n",
    "Let's apply SVD topic modeling to a set of BBC news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5acdb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "371e33ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/bbc_text.csv')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d368f",
   "metadata": {},
   "source": [
    "Let's first vectorize the input \"text\" into a vector of terms per document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ead217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 29126)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',smooth_idf=True) \n",
    "\n",
    "# under the hood - lowercasing,removing special chars,removing stop words\n",
    "DTM = vectorizer.fit_transform(df[\"text\"]).todense()\n",
    "DTM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf39c2",
   "metadata": {},
   "source": [
    "So far, we have:\n",
    "\n",
    "- identified the text corpus,\n",
    "\n",
    "-  imported the necessary modules, and\n",
    "\n",
    "- obtained the input DTM.\n",
    "\n",
    "Next, let's proceed with using SVD to obtain topics using the TruncatedSVD class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b425111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_modeling = TruncatedSVD(n_components=4, algorithm='randomized', n_iter=100, random_state=42)\n",
    "svd_modeling.n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bdde091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmui/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Users/pmui/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svd_modeling.fit(DTM)\n",
    "components=svd_modeling.components_\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0af60f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29126"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5731897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 29126)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192942f",
   "metadata": {},
   "source": [
    "Let’s write a function that gets the topics for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9ef00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_list = []\n",
    "def get_topics(components):\n",
    "    for i, comp in enumerate(components):\n",
    "        terms_comp = zip(vocab,comp)\n",
    "        sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
    "        topic = \"\"\n",
    "        for t in sorted_terms:\n",
    "            topic = topic + ' ' + t[0]\n",
    "        topic_word_list.append(topic)\n",
    "    return topic_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67d4eca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' said mr labour people year election blair',\n",
       " ' mr labour election blair brown party tax',\n",
       " ' england game win best wales ireland cup',\n",
       " ' film best awards award oscar actor actress']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topics(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00a34b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.26165116, 4.77370181, 4.21364456, 3.93105517])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_modeling.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb65a733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00311798, 0.00993334, 0.00815029, 0.00709584])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of variance explained by each of the selected components.\n",
    "\n",
    "svd_modeling.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0323b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028297453580367105"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_modeling.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "054fc6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29126"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_modeling.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813ec51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
